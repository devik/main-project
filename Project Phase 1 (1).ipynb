{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d4a42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58160cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d31e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32ef5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Define a custom document class\n",
    "class CustomDocument:\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "# Open the PDF file using PyPDF2\n",
    "pdf_file = open(\"Documents/MANDATORY-DISCLOSURE-2019-.pdf\", 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "# Create a CharacterTextSplitter with a chunk size of 500\n",
    "#text_splitter = CharacterTextSplitter(chunk_size=500)\n",
    "total_text_length = sum(len(page.extract_text()) for page in pdf_reader.pages)\n",
    "average_text_length_per_page = total_text_length / len(pdf_reader.pages)\n",
    "\n",
    "# Set a base chunk size\n",
    "base_chunk_size = 500\n",
    "\n",
    "# Calculate dynamic chunk size based on the average text length\n",
    "dynamic_chunk_size = int(average_text_length_per_page / base_chunk_size) * base_chunk_size\n",
    "\n",
    "# Create a CharacterTextSplitter with dynamic chunk size\n",
    "text_splitter = CharacterTextSplitter(chunk_size=dynamic_chunk_size)\n",
    "\n",
    "\n",
    "# Initialize a list to store the split text chunks\n",
    "split_texts = []\n",
    "\n",
    "# Loop through the PDF pages, extract text, and split into chunks\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    page = pdf_reader.pages[page_num]\n",
    "    page_text = page.extract_text()\n",
    "\n",
    "    # Split the page text into chunks\n",
    "    page_text_chunks = text_splitter.split_text(page_text)\n",
    "    split_texts.extend(page_text_chunks)\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n",
    "\n",
    "# Create a list of metadata for each document\n",
    "metadata_list = [{\"page_number\": i} for i in range(len(split_texts))]\n",
    "\n",
    "# Create a list of CustomDocument instances\n",
    "custom_documents = [CustomDocument(page_content=chunk, metadata=metadata) for chunk, metadata in zip(split_texts, metadata_list)]\n",
    "\n",
    "# Create an OpenAIEmbeddings instance or use your own embedding method\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "# Embed the split text chunks individually\n",
    "embedded_docs = [embedding_function.embed_documents(doc.page_content) for doc in custom_documents]\n",
    "\n",
    "# Initialize the Chroma vector store with the custom documents\n",
    "db = Chroma.from_documents(custom_documents, embedding_function, persist_directory=\"./test_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.text_splitter.CharacterTextSplitter"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76ead12",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what was the cut off rank for B.Tech in computer science and engineering in round 1 2019? \"\n",
    "similar_docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c795de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muthoot Institute of Technology and Science\n",
      " \n",
      "Cutoff\n",
      "2021/2020/2019\n",
      "Cut-Offs for Last Round (General Category)\n",
      "Showing Cut off values only for the years for which we have\n",
      "data\n",
      "B.Tech. in Computer Science and Engineering\n",
      "Ernakulum\n",
      "Offered by\n",
      "KTU - APJ Abdul Kalam Technological University\n",
      "Every year Muthoot Institute of Technology and Science admissions are\n",
      "conducted for the students on the basis of cut off declared by Muthoot\n",
      "Institute of Technology and Science. At Shiksha.com you can find\n",
      "Muthoot Institute of Technology and Science 2022 cut offs, for all 10\n",
      "courses offered by the college. Cut off data available on Shiksha will\n",
      "help you to apply for B.E. / B.Tech,M.E./M.Tech courses in Muthoot\n",
      "Institute of Technology and Science, Ernakulum\n",
      "KEAM\n",
      "Round\n",
      "2019\n",
      "Cut-off by rank\n",
      "2020\n",
      "Cut-off by rank\n",
      "2021\n",
      "Cut-off by rank\n",
      "1\n",
      "6385\n",
      "-\n",
      "6945\n",
      "2\n",
      "8777\n",
      "7557\n",
      "8393\n",
      "3\n",
      "9432\n",
      "9679\n",
      "5828\n",
      "Click to see KEAM Cut-Off for All Rounds\n",
      "Disclaimer:\n",
      " This PDF is auto-generated based on the information\n",
      "available on Shiksha as on 07-Sep-2022.\n"
     ]
    }
   ],
   "source": [
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce57223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6b113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.vectorstores.chroma.Chroma"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d6f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e8bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cut off rank for B.Tech in computer science and engineering in round 1 2019 was 6385.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Answer this as the administrator of the college. Only answer the question below if you have 100% certainty of the facts, use the context below to answer.\n",
    "Here is some context:\n",
    "{similar_docs[0].page_content}\n",
    "Q: {query}\n",
    "A:\"\"\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"].strip(\" \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb2b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question (or 'exit' to quit): Number of rooms in boys hostel?\n",
      "Answer: There are 70 rooms in the boys hostel.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # User input dynamically\n",
    "    user_query = input(\"Ask a question (or 'exit' to quit): \")\n",
    "\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Perform similarity search\n",
    "    similar_docs = db.similarity_search(user_query)\n",
    "\n",
    "    # Concatenate the user query and content of similar documents\n",
    "    prompt = f\"\"\"Answer this as the administrator of the college. Only answer the question below if you have 100% certainty of the facts, use the context below to answer.\n",
    "            Here is some context:\n",
    "            {similar_docs[0].page_content}\n",
    "            Q: {user_query}\n",
    "            A:\"\"\"\n",
    "    # Use the OpenAI GPT-3.5 API for text generation\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150  # You can adjust the max_tokens parameter as needed\n",
    "    )\n",
    "\n",
    "    # Get the generated answer\n",
    "    generated_answer = response[\"choices\"][0][\"text\"].strip(\" \\n\")\n",
    "\n",
    "    # Print the generated answer\n",
    "    print(\"Answer:\", generated_answer)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a0d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
